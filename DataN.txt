Java:  11.0.22 --- /usr/lib/jvm/java-ll-openjdk-amd64 hadoon@bigdatan
Hadoop: 3.3.6 --- http://192.168.0.115:9870/
Spark 3.5.6 --- Interfaz 8080 y 7077 y 4040
Pip Python 3
cluster hadoop : 9870
Kafka 3.7.2 

cd ~
ver archivos 
ls -l
ejecución en Kafka
/opt/Kafka



Archivo
/opt/kafka/kafka_producer.py

--------------------------------------Iniciar servicios desde :
HDFS: start-dfs.sh
YARN: start-yarn.sh
Zookeeper: cd ~/kafka/bin

Kafka: 

cd /opt/Kafka

sudo nohup bin/kafka-server-start.sh config/kraft/server.properties > server.log 2>&1 &

Verificar Kafka:
ps aux | grep kafka

lista tópicos, debe mostrar sensor_data

/opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092

-------------------------Jps (verificar servicios activos)
NameNode y DataNode (de HDFS)

ResourceManager y NodeManager (de YARN)

QuorumPeerMain (ZooKeeper) -

Kafka (Broker de Kafka)

--------------------------

Mis Archivos
nano batch_processing.py (archivo prueba)
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 batch_processing.py



nano kafka_producer.py (pruebas)




vi
Terminal uno: inciar servicios ZooKeeper y Kafka Broker.

Terminal dos: consumidor (enlace de datos, recibe datos y procesa)
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 spark_streaming_consumer.py

Terminal tres: productor: envia los mensajes
python3 kafka_producer_git.py

Productor: 
nano kafka_producer_git.py

python3 kafka_producer_git.py

Consumidor: 
nano spark_streaming_consumer.py

spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 
spark_streaming_consumer.py


Verificación 4040


